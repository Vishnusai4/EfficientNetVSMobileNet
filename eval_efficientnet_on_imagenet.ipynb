{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "import tensorflow_datasets as tfds \n",
    "import copy\n",
    "import math\n",
    "\n",
    "from utils.EfficientNet_model import EfficientNetB0_1, EfficientNetB1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the imagenet_v2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/valentinedhauteville/.keras/datasets/imagenet-matched-frequency-format-val\n"
     ]
    }
   ],
   "source": [
    "#Test set taken from https://github.com/modestyachts/ImageNetV2\n",
    "\n",
    "_ROOT_URL = 'https://s3-us-west-2.amazonaws.com/imagenetv2public'\n",
    "_IMAGENET_V2_URLS = {\n",
    "    'matched-frequency': _ROOT_URL + '/imagenetv2-matched-frequency.tar.gz',\n",
    "    'threshold-0.7': _ROOT_URL + '/imagenetv2-threshold0.7.tar.gz',\n",
    "    'topimages': _ROOT_URL + '/imagenetv2-topimages.tar.gz',\n",
    "}\n",
    "fname = \"imagenet_v2_matched_frequency\"\n",
    "local_file_path= tf.keras.utils.get_file(\n",
    "    fname, _IMAGENET_V2_URLS['matched-frequency'], \n",
    "    cache_subdir='datasets', hash_algorithm='auto',\n",
    "    extract=True)\n",
    "\n",
    "\n",
    "local_dir_path = os.path.dirname(local_file_path)\n",
    "data_dir = os.path.join(local_dir_path, 'imagenet-matched-frequency-format-val')\n",
    "print(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(data_dir,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  label_mode = \"categorical\",\n",
    "                                                  image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 224, 224, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "image_batch, label_batch = next(iter(validation_dataset))\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EfficientNet own versus EfficientNet Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load imagenet weights (taken off the internet) into the model we created and compare the performance with:\n",
    "* The keras implementation loaded with imagenet weights (that is instantiated with the weights = \"imagenet\" parameter. We use this as the reference. In the best of worlds, this should give us a performance similar to the official paper's ( ~77.1% top-1 accuracy)\n",
    "* The keras implementation loaded with imagenet weights we used for our model. This should give us the same performance as our model's, otherwise this means something is off with our implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of layers\n",
    "\n",
    "model0_1 = EfficientNetB0_1()\n",
    "print(f\"num_layers in self implemented: {len(model0_1.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the keras model as reference\n",
    "\n",
    "#with imagenet weights\n",
    "model0 = EfficientNetB0(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "#no pretrained weights\n",
    "model00 = EfficientNetB0(weights= None, include_top=True)\n",
    "print(f\"num_layers total keras: {len(model00.layers)}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers trainable in self implemented EfficientNet_B0: 132\n",
      "num_layers trainable in keras EfficientNet-B0: 132\n"
     ]
    }
   ],
   "source": [
    "#Number of layers with parameters/weights\n",
    "\n",
    "layers = model0_1.layers\n",
    "filtered_layers = []\n",
    "for layer in layers:\n",
    "    weights = layer.weights\n",
    "    if weights:\n",
    "        filtered_layers.append(layer)\n",
    "print(f\"num_layers trainable in self implemented EfficientNet_B0: {len(filtered_layers)}\" )        \n",
    "\n",
    "layers = model00.layers\n",
    "filtered_layers = []\n",
    "for layer in layers:\n",
    "    weights = layer.weights\n",
    "    if weights:\n",
    "        filtered_layers.append(layer)\n",
    "\n",
    "print(f\"num_layers trainable in keras EfficientNet-B0: {len(filtered_layers)}\" )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model0_1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model00.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Get the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried three different optional repositories for the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers trainable in self implemented EfficientNet_B0: 132\n",
      "num_layers trainable in keras EfficientNet-B0: 132\n"
     ]
    }
   ],
   "source": [
    "#Number of layers with parameters/weights\n",
    "\n",
    "layers = model0_1.layers\n",
    "filtered_layers = []\n",
    "for layer in layers:\n",
    "    weights = layer.weights\n",
    "    if weights:\n",
    "        filtered_layers.append(layer)\n",
    "print(f\"num_layers trainable in self implemented EfficientNet_B0: {len(filtered_layers)}\" )        \n",
    "\n",
    "layers = model00.layers\n",
    "filtered_layers = []\n",
    "for layer in layers:\n",
    "    weights = layer.weights\n",
    "    if weights:\n",
    "        filtered_layers.append(layer)\n",
    "\n",
    "print(f\"num_layers trainable in keras EfficientNet-B0: {len(filtered_layers)}\" )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: From the official TPU repo \n",
    "#https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\n",
    "# utils/efficientnet_weight_update_util.py is a script copied from https://github.com/tensorflow/\n",
    "#tensorflow/blob/master/tensorflow/python/keras/applications/efficientnet_weight_update_util.py\n",
    "# to convert a ckpt file to h5 file\n",
    "def download_weights_from_tpu_repo(model_name):\n",
    "    !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/ckpts/{model_name}.tar.gz -O {model_name}.tar.gz\n",
    "    !tar xf {model_name}.tar.gz\n",
    "\n",
    "    !wget https://raw.githubusercontent.com/tensorflow/tensorflow\\\n",
    "        /master/tensorflow/python/keras/applications/efficientnet_weight_update_util.py\n",
    "    # convert to H5\n",
    "    !python utils/efficientnet_weight_update_util.py --model b0 --ckpt \\\n",
    "            {model_name}/model.ckpt --o {model_name}.h5\n",
    "\n",
    "    weights_path = f\"{model_name}.h5\"\n",
    "    return weights_path\n",
    "\n",
    "#Method 2, using checkpoints published on https://github.com/qubvel/efficientnet/\n",
    "def download_weights_from_individual_contrib(model_name):\n",
    "    !wget https://github.com/qubvel/efficientnet/releases/download/v0.0.1/{model_name}_imagenet_1000.h5\n",
    "    weights_path = f\"model_name_imagenet_1000.h5\"\n",
    "    return weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Method 3: from the Keras source code. The hash below corresponds to EfficientNetB0 weights\n",
    "\n",
    "# file_suff = '_weights_tf_dim_ordering_tf_kernels_autoaugment.h5'\n",
    "# file_hash = 'e9e877068bd0af75e0a36691e03c072c' #file hash for B0\n",
    "# model_name = \"efficientnet-b0\"\n",
    "# file_name =  model_name + file_suff\n",
    "# BASE_WEIGHTS_PATH = (\n",
    "#     'https://github.com/Callidior/keras-applications/'\n",
    "#     'releases/download/efficientnet/')\n",
    "\n",
    "# weights_path = tf.keras.utils.get_file(file_name, \n",
    "#                                        BASE_WEIGHTS_PATH + file_name,\n",
    "#                                        cache_subdir='models', file_hash=file_hash)\n",
    "\n",
    "# model_1.load_weights(weights_path, by_name=True)\n",
    "# model_00.load_weights(weights_path, by_name=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=5)\n",
    "top5_acc.__name__ = 'top5_acc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1347s 2s/step - loss: 1.8168 - accuracy: 0.5971 - top5_acc: 0.8214\n",
      "Test accuracy : 0.597100019454956\n"
     ]
    }
   ],
   "source": [
    "#Keras model with pretrained ImageNet weights\n",
    "model0.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', top5_acc])\n",
    "\n",
    "loss, accuracy, top5_acc = model0.evaluate(validation_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-19 23:23:02--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/ckpts/efficientnet-b0.tar.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4007:80c::2010, 2a00:1450:4007:810::2010, 2a00:1450:4007:812::2010, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4007:80c::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47390720 (45M) [application/gzip]\n",
      "Saving to: ‘efficientnet-b0.tar.gz’\n",
      "\n",
      "efficientnet-b0.tar 100%[===================>]  45.20M   525KB/s    in 2m 19s  \n",
      "\n",
      "2020-12-19 23:25:24 (332 KB/s) - ‘efficientnet-b0.tar.gz’ saved [47390720/47390720]\n",
      "\n",
      "--2020-12-19 23:25:24--  https://raw.githubusercontent.com/tensorflow/tensorflow\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.120.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.120.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 400 Bad Request\n",
      "2020-12-19 23:25:26 ERROR 400: Bad Request.\n",
      "\n",
      "/master/tensorflow/python/keras/applications/efficientnet_weight_update_util.py: Scheme missing.\n",
      "2020-12-19 23:25:34.644704: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 23:25:34.685565: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ef7e5f3f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 23:25:34.685595: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block2a match.\n",
      "blocks_2 and block2b match.\n",
      "blocks_3 and block3a match.\n",
      "blocks_4 and block3b match.\n",
      "blocks_5 and block4a match.\n",
      "blocks_6 and block4b match.\n",
      "blocks_7 and block4c match.\n",
      "blocks_8 and block5a match.\n",
      "blocks_9 and block5b match.\n",
      "blocks_10 and block5c match.\n",
      "blocks_11 and block6a match.\n",
      "blocks_12 and block6b match.\n",
      "blocks_13 and block6c match.\n",
      "blocks_14 and block6d match.\n",
      "blocks_15 and block7a match.\n",
      "skipping variable normalization/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "311/314 weights updated\n"
     ]
    }
   ],
   "source": [
    "weights_path = download_weights_from_tpu_repo(\"efficientnet-b0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1247s 2s/step - loss: 3.0190 - accuracy: 0.3994 - top5_acc: 0.6435\n",
      "Test accuracy : 0.399399995803833\n"
     ]
    }
   ],
   "source": [
    "#Keras model with our downloaded ImageNet weights\n",
    "\n",
    "model00.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', top5_acc])\n",
    "\n",
    "model00.load_weights(weights_path, by_name=True)\n",
    "\n",
    "loss, accuracy, top_5 = model00.evaluate(validation_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1207s 2s/step - loss: 3.0659 - accuracy: 0.3963 - top5_acc: 0.6353\n",
      "Test accuracy : 0.39629998803138733\n"
     ]
    }
   ],
   "source": [
    "model0_1.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', top5_acc])\n",
    "\n",
    "model0_1.load_weights(weights_path,  by_name=True)\n",
    "\n",
    "loss, accuracy, top_5 = model0_1.evaluate(validation_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
